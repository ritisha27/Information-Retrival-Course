{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "raNcZcamCoMA",
        "wpQyX2WQCuqP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1. Import the Libraries"
      ],
      "metadata": {
        "id": "raNcZcamCoMA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QYTw6LVbBsQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71b891a4-9fb4-41f1-ee51-b89e7f1dcb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# To unzip the zipped file.\n",
        "import zipfile\n",
        "# To check if the file in path already exists or not\n",
        "import os\n",
        "# To split the train set to train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "# For text based pre-processing\n",
        "import nltk\n",
        "# For punctuation removal\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# TO execute Lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "import math\n",
        "\n",
        "# To use Inbuilt- TF-IDF Vectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Pickle Files - \n",
        "import pickle\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z86DL0xDfYq",
        "outputId": "a4405858-7704-4c5c-c118-c94c5cc84d73"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Unzip and Load the Dataset"
      ],
      "metadata": {
        "id": "wpQyX2WQCuqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE -  Here we load the Dataset in the folder Data-Q2 and check if the folder already exists. If the folder already exists, the files are not unzipped again."
      ],
      "metadata": {
        "id": "6HZg9omJFl8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZqkzAZVp7-b",
        "outputId": "d6e9836f-7bfd-4b46-c799-b510f0cc0cac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "par_dir = '/content/drive/MyDrive/IR/Assignment'"
      ],
      "metadata": {
        "id": "fd0csun3qPq1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the name of the Directory\n",
        "my_dir = 'Data-Q2'\n",
        "# Parent Directory path\n",
        "par_dir = '/content/drive/MyDrive/IR/Assignment'\n",
        "    \n",
        "# Path to the new directory\n",
        "path = os.path.join(par_dir,my_dir)"
      ],
      "metadata": {
        "id": "4od9sRM8qqBx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.isdir(path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5-kZE9bpcJL",
        "outputId": "f60a08f2-620e-4918-ad85-44bf2bfe1116"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (os.path.isdir(path)==False):\n",
        "\n",
        "  # Make the new directory\n",
        "  os.mkdir(path)\n",
        "  print(\"Directory '% s' created\" % my_dir)\n",
        "\n",
        "  # Unzip the Zipped FIle\n",
        "  zip = path + '/BBC-News.zip'\n",
        "  with zipfile.ZipFile(zip, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path)"
      ],
      "metadata": {
        "id": "ZkWAtwEGC74d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Train and Test Data from the Dataset loaded in the Target Directory"
      ],
      "metadata": {
        "id": "5AHQSDavIZS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = path + '/BBC News Train.csv'\n",
        "test_path = path + '/BBC News Test.csv'"
      ],
      "metadata": {
        "id": "MxWPJwjwIkVU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df =  pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)"
      ],
      "metadata": {
        "id": "x7ugLuyCFYzC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCGH9_7AJLME",
        "outputId": "167c22a0-c745-46b0-8d72-7ac6bb54157a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ArticleId                                               Text  Category\n",
            "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
            "1        154  german business confidence slides german busin...  business\n",
            "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
            "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
            "4        917  enron bosses in $168m payout eighteen former e...  business\n",
            "   ArticleId                                               Text\n",
            "0       1018  qpr keeper day heads for preston queens park r...\n",
            "1       1319  software watching while you work software that...\n",
            "2       1138  d arcy injury adds to ireland woe gordon d arc...\n",
            "3        459  india s reliance family feud heats up the ongo...\n",
            "4       1020  boro suffer morrison injury blow middlesbrough...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the column header of the Dataframes\n",
        "my_lst = list(train_df.columns)\n",
        "print(my_lst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyrp3diyOC_Q",
        "outputId": "b5c624c0-2abc-49f0-cee0-f0d80a743455"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ArticleId', 'Text', 'Category']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all unique categories.\n",
        "my_lst = list(train_df['Category'].unique())\n",
        "all_class = len(my_lst)\n",
        "print(my_lst)\n",
        "print(all_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uIqelJHO6n2",
        "outputId": "534d89fa-1b7d-4c36-e74d-b532784b8b06"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['business', 'tech', 'politics', 'sport', 'entertainment']\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observation -  The train set consists of three columns namely S.NO , ArticleID, the TEXT and the Category."
      ],
      "metadata": {
        "id": "K3jt3bOZJami"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates and remove if any.\n",
        "dup = train_df[train_df.duplicated()]\n",
        "print(dup)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RI7fIvzDvp1d",
        "outputId": "e86a1721-2841-4222-d8e3-b2aa92f57849"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [ArticleId, Text, Category]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove all dupluacte rows\n",
        "train_df = train_df.drop_duplicates(keep=False)"
      ],
      "metadata": {
        "id": "WmSdASxQwVxY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Pre-processing the Dataset\n",
        "The dataset is in CSV format with the following columns: ‘ArticleId’, 'Text', and\n",
        "'Category'.\n",
        "\n",
        "● Remove any unnecessary columns.\n",
        "\n",
        "● Clean the text by removing punctuation, stop words, and converting all text to\n",
        "lowercase.\n",
        "\n",
        "● Tokenize the text by splitting it into words.\n",
        "\n",
        "● Perform stemming or lemmatization to reduce words to their root form.\n",
        "\n",
        "● Implement the TF-ICF weighting scheme.\n"
      ],
      "metadata": {
        "id": "uQPunzaqPc-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for null rows/samples in the Train and Test Dataframes\n",
        "print(train_df.isnull().values.any())\n",
        "print(test_df.isnull().values.any())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdrvmoQ2Pijp",
        "outputId": "aa30ada6-9d84-4fe0-b740-93f952d8408d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = train_df['Category'].value_counts()\n",
        "print(my_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsb_q5Ksmxwv",
        "outputId": "99d0216c-21f7-4f29-f04a-83d275658158"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sport            346\n",
            "business         336\n",
            "politics         274\n",
            "entertainment    273\n",
            "tech             261\n",
            "Name: Category, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"ticks\")\n",
        "sns.set_style(\"darkgrid\")\n",
        "sns.countplot(x ='Category', data = train_df,palette='mako')\n",
        "plt.title(\"Visualising the Data Distribution in the Train Set\")\n",
        "plt.xlabel ('Category of News')\n",
        "plt.ylabel ('Count of Data')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "QSaw9JlIrp8E",
        "outputId": "b0160404-67e6-42e8-b802-60a2fb52fbab"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE - The train dataset is not perfectly balanced, but is not highly imbalanced."
      ],
      "metadata": {
        "id": "xq_Lyxhired6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = train_df['Category']\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjLvmuCSxhrz",
        "outputId": "0a06679e-3371-4cd2-b882-16172f935646"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0            business\n",
            "1            business\n",
            "2            business\n",
            "3                tech\n",
            "4            business\n",
            "            ...      \n",
            "1485    entertainment\n",
            "1486    entertainment\n",
            "1487         business\n",
            "1488             tech\n",
            "1489             tech\n",
            "Name: Category, Length: 1490, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = train_df.copy()\n",
        "X.drop('Category',axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "qSapDcvVxtv2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "Q6MF2fy9dYC6",
        "outputId": "171bbc7e-dae7-430a-fba8-1e878d76676c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ArticleId                                               Text  Category\n",
              "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
              "1        154  german business confidence slides german busin...  business\n",
              "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
              "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
              "4        917  enron bosses in $168m payout eighteen former e...  business"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2b21679e-277b-4d2e-8c90-ee0e817e1361\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1833</td>\n",
              "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>154</td>\n",
              "      <td>german business confidence slides german busin...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1101</td>\n",
              "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1976</td>\n",
              "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>917</td>\n",
              "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b21679e-277b-4d2e-8c90-ee0e817e1361')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2b21679e-277b-4d2e-8c90-ee0e817e1361 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2b21679e-277b-4d2e-8c90-ee0e817e1361');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first sample text example ( before pre-processing)\n",
        "print(X['Text'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PbuhWyyyB6t",
        "outputId": "21ce4148-b782-432f-bc92-9b53f752f8d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.  cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud. mr ebbers has pleaded not guilty to charges of fraud and conspiracy.  prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates. but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom. mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.  ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself. the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books . however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting. mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing. worldcom emerged from bankruptcy protection in 2004  and is now known as mci. last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VspKnwZDyGWD",
        "outputId": "32cf8727-9a48-472c-e6e1-707f1cea120b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ArticleId                                               Text\n",
            "0          1833  worldcom ex-boss launches defence lawyers defe...\n",
            "1           154  german business confidence slides german busin...\n",
            "2          1101  bbc poll indicates economic gloom citizens in ...\n",
            "3          1976  lifestyle  governs mobile choice  faster  bett...\n",
            "4           917  enron bosses in $168m payout eighteen former e...\n",
            "...         ...                                                ...\n",
            "1485        857  double eviction from big brother model caprice...\n",
            "1486        325  dj double act revamp chart show dj duo jk and ...\n",
            "1487       1590  weak dollar hits reuters revenues at media gro...\n",
            "1488       1587  apple ipod family expands market apple has exp...\n",
            "1489        538  santy worm makes unwelcome visit thousands of ...\n",
            "\n",
            "[1490 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The punctuations exist in string.punctuations are used to eliminate the punctuations.\n",
        "print(string.punctuation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPPxnOjG11uv",
        "outputId": "128868d3-ed37-408f-d262-bdcfd8af5828"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for all the stopwords and the stopwords are eliminated from the text during pre-processing.\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHlL9MBmXMkU",
        "outputId": "b3180a46-aa4e-4a81-e978-2a2c564edfd2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuations, stop-words and convert all text to lower-case\n",
        "def my_preprocess_text(input_text,stem_on,lemma_on):\n",
        "  #------------------------------Remove Punctuations----------------------#\n",
        "  # Removing punctuations in string\n",
        "  my_str = str(input_text)\n",
        "  set_punct = string.punctuation\n",
        "  # Using loop + punctuation string\n",
        "  for word in my_str:\n",
        "    if word in set_punct:\n",
        "      my_str = my_str.replace(word, \"\")\n",
        "\n",
        "\n",
        "  #-------------------------Convert to Lower Case--------------------------#\n",
        "  my_str = my_str.lower()\n",
        "  \n",
        "  #-----------------------------Remove Stopwords---------------------------#\n",
        "  from nltk.corpus import stopwords\n",
        "  from nltk.tokenize import word_tokenize\n",
        "  set_stopwords = set(stopwords.words('english'))\n",
        "  # Pass the processed string here\n",
        "  my_tokens = nltk.word_tokenize(my_str)\n",
        "  my_ans = []\n",
        "  for w in my_tokens:\n",
        "    if w not in set_stopwords:\n",
        "      my_ans.append(w)\n",
        "  #print(my_ans)\n",
        "\n",
        "  # Get back the string to use an input for Lemmatizer\n",
        "  my_str = \"\"\n",
        "  # Traverse in the string\n",
        "  for word in my_ans:\n",
        "        my_str += word\n",
        "        my_str += \" \"\n",
        "\n",
        "\n",
        "  #----------------------------Stemming------------------------------#\n",
        "  from nltk.stem import PorterStemmer\n",
        "  if(stem_on == 'Yes'):\n",
        "    my_res = []\n",
        "    my_tokens = nltk.word_tokenize(my_str)\n",
        "    # importing modules\n",
        "    ps = PorterStemmer()\n",
        "    for w in my_tokens:\n",
        "      my_stem = ps.stem(w)\n",
        "      my_res.append(my_stem)\n",
        "      #print(\"Lemma for {} is {}\".format(w,lemma))\n",
        "      #print(my_res)\n",
        "      # Get back the string to return the processed string.\n",
        "    my_str = \"\"\n",
        "    # Traverse in the string\n",
        "    for word in my_res:\n",
        "      my_str += word\n",
        "      my_str += \" \"\n",
        "\n",
        "  #-----------------------Lemmatization-------------------------------------#\n",
        "  from nltk.stem import WordNetLemmatizer\n",
        "  if(lemma_on == 'Yes'):\n",
        "    my_lemmatizer = WordNetLemmatizer()\n",
        "    # Reduce the words to their root form\n",
        "    my_tokens = nltk.word_tokenize(my_str)\n",
        "    my_res = []\n",
        "    for w in my_tokens:\n",
        "      lemma = my_lemmatizer.lemmatize(w)\n",
        "      my_res.append(lemma)\n",
        "      #print(\"Lemma for {} is {}\".format(w,lemma))\n",
        "      #print(my_res)\n",
        "      # Get back the string to return the processed string.\n",
        "    my_str = \"\"\n",
        "    # Traverse in the string\n",
        "    for word in my_res:\n",
        "      my_str += word\n",
        "      my_str += \" \"\n",
        "  \n",
        "\n",
        "  return my_str"
      ],
      "metadata": {
        "id": "lyHqDH2O00NR"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example to check appropriate pre-processing\n",
        "my_preprocess_text('I am studies !@','Yes','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "g2b065QHrwxL",
        "outputId": "ebc5d921-4a86-4a08-894d-b4e7b77cbb7d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'studi '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "GqFH1CyFdSyz",
        "outputId": "d1f6eed9-854a-4170-e23f-714a1288fa01"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ArticleId                                               Text  Category\n",
              "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
              "1        154  german business confidence slides german busin...  business\n",
              "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
              "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
              "4        917  enron bosses in $168m payout eighteen former e...  business"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ebabea6-ad93-45b9-90c6-0f1aaa78218f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1833</td>\n",
              "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>154</td>\n",
              "      <td>german business confidence slides german busin...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1101</td>\n",
              "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1976</td>\n",
              "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>917</td>\n",
              "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ebabea6-ad93-45b9-90c6-0f1aaa78218f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ebabea6-ad93-45b9-90c6-0f1aaa78218f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ebabea6-ad93-45b9-90c6-0f1aaa78218f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing the preprocessing on the etnire Training Dataframe\n",
        "#train_df['Text'] = train_df['Text'].apply(preprocess_text)\n",
        "# Get the Text in the new dataframe. Used for processing further.\n",
        "#X['Text'] = train_df['Text']"
      ],
      "metadata": {
        "id": "O7XjmCuVJAud"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. The Dataset:\n",
        "\n",
        "● Split the BBC train dataset into training and testing sets.\n",
        "\n",
        "● Use a 70:30 split for the training and testing sets, respectively."
      ],
      "metadata": {
        "id": "Sz1ifHFcPnti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As the Train - Test split is in the specified ratio as 70:30 and hence the test_size is set to 30% only\n",
        "def get_split(X,y,split_ratio):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split_ratio, random_state=42, stratify=y)\n",
        "  print(\"The no. of samples in Training Set is as : \",X_train.shape[0])\n",
        "  print(\"The no. of samples in the Test Set is as \",X_test.shape[0])\n",
        "  return X_train,X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "9i_6Vc_6P6YC"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train,X_test, y_train, y_test = get_split(X,y,0.30)"
      ],
      "metadata": {
        "id": "jG74tLoKVMil"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example after processing.\n",
        "#X_train['Text'][0]"
      ],
      "metadata": {
        "id": "KhVa5jXXJ6XT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOTE : -  Implementing the TF-ICF Weighting Scheme\n",
        "Term Frequency (TF): Number of occurrences of a term in all documents of a particular class.\n",
        "\n",
        "Class Frequency (CF): Number of classes in which that term occurs.\n",
        "\n",
        "Inverse-Class Frequency (ICF): log( N / CF), where N represents the number of classes (log 10).\n"
      ],
      "metadata": {
        "id": "dhGj5JKgLzQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train['Text'][0].split()"
      ],
      "metadata": {
        "id": "bMuAYvqHe7Xh"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_train[0]"
      ],
      "metadata": {
        "id": "DsdtO7IUhuBI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTION DEFINITION - get_tf(X,y)  :\n",
        "\n",
        "Get the Training Data i.e. the text samples in X_train and corresponding labels or category for each row of text in y_train and evaluates the count of each term i.e. the term frequency for each of the term, corresponding to  a gievn category and hence the function returns a dictionary of dictionaries where the outer key consists of the labels or the categories and the inner values correspond to another nested dictionary consisting of the the term as the key and the corresponding frequency as the value and hence form a key-value pair for the nested dictionary. \n",
        "\n",
        "NOTE - If a word exists in a document 'n' no of times, then all of its occurences are evaluated as the term frequency of the term for the label in a specific document. Next if the term appears in another document corresponding to the same label, the frequency is increemented accordingly. The function also evalautes the count of documents in which a term occurs and hence returns the second structure as a dictionary which consists of the a unique term as the key and the no. of documents in which the term appears at least once."
      ],
      "metadata": {
        "id": "9Gp0SkLIl3tS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input - (data) - It is a dataframe which has all the columns as X  - 'Text' and the y labels are as 'Category'.\n",
        "def get_tf(X,y):\n",
        "  length = X.shape[0]\n",
        "  #print(len)\n",
        "  tf_dict = {}\n",
        "  cat_list = {}\n",
        "  # Iterate over all the data samples ( Text Samples)\n",
        "  for i in X.index:\n",
        "    # Iterate over each word in the given Training Set\n",
        "    for word in X['Text'][i].split():\n",
        "      # Get the category for the current piece of text being explored.\n",
        "      label = y[i]\n",
        "      if label in tf_dict:\n",
        "        if word in tf_dict[label]:\n",
        "          tf_dict[label][word] = tf_dict[label][word] + 1\n",
        "        else:\n",
        "          tf_dict.setdefault(label, {})[word] = 1 \n",
        "      else:\n",
        "        tf_dict.setdefault(label, {})[word] = 1 \n",
        "    # Find the documents which consist of a specific word.\n",
        "    # NOTE - This does not stores the repeated occurence of the word\n",
        "    for word in set(X['Text'][i].split()):\n",
        "      if word in cat_list:\n",
        "        cat_list[word] = cat_list[word] + 1\n",
        "      else:\n",
        "        cat_list.update({word:1})\n",
        "  return tf_dict,cat_list"
      ],
      "metadata": {
        "id": "syNH-4BWK9zb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTION DEFINITION  - get_icf:\n",
        "\n",
        "The function to evaluate the Inverse Category Frequnecy. The input to the function is the dictionary of dictionaries for the term frequency. We first iterate over the keys in the nested dictionary corresponding to the label/category values in the outer dictionary and next, if the given term exists as a key correspoding to one or more labels we increement the category count and evaluate the ICF for the given word using the log of ratio of all categories over the count of categories in which the term exists."
      ],
      "metadata": {
        "id": "JBmio1jrpAQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate ICF ( Inverse - Class Frequency )\n",
        "# Class Frequnecy  - No. of classes in which the term occurs.\n",
        "def get_icf(my_tf_dict, vocabulary, all_class):\n",
        "  icf = {}\n",
        "  cat_count = 0\n",
        "  for word in vocabulary.keys():\n",
        "    # Count the no. of categories to which a word belongs.\n",
        "    cat_count = 0\n",
        "    # Find the answer as for which categories the word exists.\n",
        "    for out_key, in_key_dict in my_tf_dict.items():\n",
        "      if word in in_key_dict:\n",
        "          cat_count = cat_count + 1\n",
        "    #print('Word',word,'Count',cat_count)\n",
        "    # Add one for the case of smoothing veikctor \n",
        "    icf[word] = math.log(all_class/cat_count,10)\n",
        "\n",
        "  return icf"
      ],
      "metadata": {
        "id": "-13xBPJAfHuL"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTION DEFINITION - get_idf:\n",
        "\n"
      ],
      "metadata": {
        "id": "E7UCU5kMse-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_idf(my_vocab,all_doc_train):\n",
        "  idf_dict = {}\n",
        "  for word in my_vocab.keys():\n",
        "    idf_dict[word] = math.log(all_doc_train/my_vocab[word],10)\n",
        "  return idf_dict"
      ],
      "metadata": {
        "id": "NQSYQwB5bMld"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTION DEFINITION - get_tf_icf"
      ],
      "metadata": {
        "id": "-RT7GZMmsow7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tf_icf(my_tf_dict,icf_dict):\n",
        "  tf_icf_dict = {}\n",
        "  # Get the label of the category\n",
        "  for label in my_tf_dict:\n",
        "    # Get the words corresponding to the given label\n",
        "    for word in my_tf_dict[label].keys():\n",
        "      tf_val = my_tf_dict[label][word]\n",
        "      icf_val = icf_dict[word]\n",
        "      if label in tf_icf_dict:\n",
        "        if word in tf_icf_dict[label]:\n",
        "          tf_icf_dict[label][word] = tf_val * icf_val\n",
        "        else:\n",
        "           tf_icf_dict.setdefault(label, {})[word] = tf_val * icf_val\n",
        "      else:\n",
        "        tf_icf_dict.setdefault(label, {})[word] = tf_val * icf_val\n",
        "  return tf_icf_dict"
      ],
      "metadata": {
        "id": "Di5Ms3x_QVzU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCTION DEFINITION - get_tf_idf"
      ],
      "metadata": {
        "id": "59dDOSxxsrzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_tf_idf(my_tf_dict,idf_dict):\n",
        "  tf_idf_dict = {}\n",
        "  # Get the label of the category\n",
        "  for label in my_tf_dict:\n",
        "    # Get the words corresponding to the given label\n",
        "    for word in my_tf_dict[label].keys():\n",
        "      tf_val = my_tf_dict[label][word]\n",
        "      idf_val = idf_dict[word]\n",
        "      if label in tf_idf_dict:\n",
        "        if word in tf_idf_dict[label]:\n",
        "          tf_idf_dict[label][word] = tf_val * idf_val\n",
        "        else:\n",
        "           tf_idf_dict.setdefault(label, {})[word] = tf_val * idf_val\n",
        "      else:\n",
        "        tf_idf_dict.setdefault(label, {})[word] = tf_val * idf_val\n",
        "  return tf_idf_dict"
      ],
      "metadata": {
        "id": "dI6i4kD_w45z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test Code ( Print Statements to print and verify intermediate "
      ],
      "metadata": {
        "id": "73xpVGYhtp2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X)"
      ],
      "metadata": {
        "id": "_KGp4FS-K5UO"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X_train)"
      ],
      "metadata": {
        "id": "eAyuiX8tK76h"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X_train['Text'][466])"
      ],
      "metadata": {
        "id": "psZrfH1wLFSM"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tf_dict,my_vocab = get_tf(X_train,y_train)"
      ],
      "metadata": {
        "id": "133U0XV1VUnf"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(my_vocab)"
      ],
      "metadata": {
        "id": "J84c95PTE7UL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(tf_dict.keys())"
      ],
      "metadata": {
        "id": "-qBIwcLY_QqJ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(tf_dict['business'].keys())"
      ],
      "metadata": {
        "id": "CNHPRQQKqCdY"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sort_vocab = dict(sorted(my_vocab.items(), key=lambda item: item[1]))\n",
        "#print(len(sort_vocab))"
      ],
      "metadata": {
        "id": "Y9G6NzW8PhCp"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for out_key, in_key_dict in tf_dict.items():\n",
        "   #print(f\"Outer key: {out_key}\")\n",
        "   #print(in_key_dict)"
      ],
      "metadata": {
        "id": "swTZ9EY7k38j"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all_doc_train = len(X_train)"
      ],
      "metadata": {
        "id": "kk2acwX-ncOO"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#icf_dict = get_icf(tf_dict, my_vocab, all_class)"
      ],
      "metadata": {
        "id": "TtNbGeakMp8r"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#idf_dict = get_idf(my_vocab,all_doc_train)"
      ],
      "metadata": {
        "id": "j6lzXt3luR6H"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(idf_dict)"
      ],
      "metadata": {
        "id": "p7YJCuqzwscT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(icf_dict)"
      ],
      "metadata": {
        "id": "T7v1lq13lnhT"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tf_icf_dict = get_tf_icf(tf_dict,icf_dict)"
      ],
      "metadata": {
        "id": "ohSzdRQ6UJ5_"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tf_idf_dict = get_tf_idf(tf_dict,idf_dict)"
      ],
      "metadata": {
        "id": "n3h3eUPYyIH9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(tf_idf_dict)"
      ],
      "metadata": {
        "id": "53F2UKRhyRgl"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(tf_icf_dict)"
      ],
      "metadata": {
        "id": "LQDsYp3OU5yA"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing the TF-ICF Weighing."
      ],
      "metadata": {
        "id": "6ge-49XCI-nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(X_test)"
      ],
      "metadata": {
        "id": "pcAf6mEseb74"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Training the Naive Bayes classifier with TF-ICF:\n",
        "\n",
        "● Implement the Naive Bayes classifier with the TF-ICF weighting scheme.\n",
        "\n",
        "● Calculate the probability of each category based on the frequency of documents in the training set that belong to that category.\n",
        "\n",
        "● Calculate the probability of each feature given each category based on the TF-ICF values of that feature in documents belonging to that category."
      ],
      "metadata": {
        "id": "1pLgXVNlP60R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NaiveBayesClassifier:\n",
        "  def __init__(self):\n",
        "    self.category_count = {}\n",
        "    self.all_articles = 0\n",
        "    self.tf_dict = {}\n",
        "    self.icf_dict = {}\n",
        "    self.tf_icf_dict = {}\n",
        "    self.tf_idf_dict = {}\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------------TRAIN-----------------------------------------------------------------------------------#\n",
        "\n",
        "  def train(self,X,y,tf_dict,icf_dict,tf_icf_dict,tf_idf_dict):\n",
        "    # How many documents of each category exists. -> Find the total no. of documents in each category.\n",
        "    for i in X.index:\n",
        "      label = y[i]\n",
        "      if label in self.category_count:\n",
        "        self.category_count[label] = self.category_count[label] + 1\n",
        "      else:\n",
        "           self.category_count.setdefault(label,1)\n",
        "    # Assign the evaluated values on the Train Data to the class variables.\n",
        "    self.all_articles  = X.shape[0]\n",
        "    self.tf_dict = tf_dict\n",
        "    self.tf_icf_dict = tf_icf_dict\n",
        "    self.tf_idf_dict = tf_idf_dict\n",
        "    # print(self.category_count)\n",
        "    # Remember - The function 'predict' takes in input as the processed text in a row.\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------------PREDICT TF_ICF----------------------------------------------------------------------------------#\n",
        "\n",
        "  def predict(self,test_txt):\n",
        "    log_prob_dict = {}\n",
        "    cat_prob_dict = {}\n",
        "    #print(self.category_count.keys())\n",
        "    #print(self.all_articles)\n",
        "    for label in self.category_count.keys():\n",
        "      #print(label)\n",
        "      # category_count[label] -  Total no. of training examples for the label\n",
        "      #------------------------------------------------------------------------------------------------------------------------------------------#\n",
        "      if label in cat_prob_dict:\n",
        "        # The probability of label i.e. what is the class probability from amongst all given articles, what is the probability of occurence of a specific class.\n",
        "        #print('In if loop')\n",
        "        cat_prob_dict[label] = (self.category_count[label]/self.all_articles)\n",
        "      else:\n",
        "        #print('Out of if loop', self.category_count[label]/self.all_articles )\n",
        "        cat_prob_dict.update({label:self.category_count[label]/self.all_articles})\n",
        "\n",
        "\n",
        "      # Now predict on the basis of input word.\n",
        "      # What is the term frequency of the given word for given specific category\n",
        "      # We iterate over all the categories, to find out the maximum probability of the word to exist in one of the specified category.\n",
        "      for label in cat_prob_dict.keys():\n",
        "        #print(\"EVALUATING FOR LABEL ---------\", label)\n",
        "        for word in test_txt.split():\n",
        "          #tf = self.tf_dict[label][word]\n",
        "          #icf = self.icf_dict.get(word,0)\n",
        "          #log_prob_dict[label] += self.tf_icf_dict[label][word] / (sum(self.tf_dict[label].values()) + len(self.icf_dict))\n",
        "          if label in log_prob_dict:\n",
        "            if word in self.tf_icf_dict[label]:\n",
        "              log_prob_dict[label] += self.tf_icf_dict[label][word]\n",
        "            else:\n",
        "              log_prob_dict[label] += 0\n",
        "          else:\n",
        "            log_prob_dict.update({label:0})\n",
        "\n",
        "#------------Multiplying term queries with category priors--------------------------------#\n",
        "      for label in cat_prob_dict.keys():\n",
        "        log_prob_dict[label] = log_prob_dict[label]*cat_prob_dict[label]\n",
        "\n",
        "        #print('HI')f\n",
        "\n",
        "    res_class = None\n",
        "    # Initialize the maximum value to negative infinity\n",
        "    max_log_prob = float('-inf')\n",
        "    # Iterate over the category and the corresponding label values to get the maximum value of probability and then return the corresponding class.\n",
        "\n",
        "    for label, log_prob in log_prob_dict.items():\n",
        "      #print(log_prob)\n",
        "      if log_prob > max_log_prob:\n",
        "        max_class = label\n",
        "        max_log_prob = log_prob\n",
        "    return max_class\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------------------------PREDICT TF-ICF-----------------------------------------------------------------------------------------------------------------#\n",
        "  def predict_tf_idf(self,test_txt):\n",
        "      log_prob_dict = {}\n",
        "      cat_prob_dict = {}\n",
        "      #print(self.category_count.keys())\n",
        "      #print(self.all_articles)\n",
        "      for label in self.category_count.keys():\n",
        "        #print(label)\n",
        "        # category_count[label] -  Total no. of training examples for the label\n",
        "        #------------------------------------------------------------------------------------------------------------------------------------------#\n",
        "        if label in cat_prob_dict:\n",
        "          # The probability of label i.e. what is the class probability from amongst all given articles, what is the probability of occurence of a specific class.\n",
        "          print('In if loop')\n",
        "          cat_prob_dict[label] = (self.category_count[label]/self.all_articles)\n",
        "        else:\n",
        "          #print('Out of if loop', self.category_count[label]/self.all_articles )\n",
        "          cat_prob_dict.update({label:self.category_count[label]/self.all_articles})\n",
        "\n",
        "\n",
        "        # Now predict on the basis of input word.\n",
        "        # What is the term frequency of the given word for given specific category\n",
        "        # We iterate over all the categories, to find out the maximum probability of the word to exist in one of the specified category.\n",
        "        for label in cat_prob_dict.keys():\n",
        "          #print(\"EVALUATING FOR LABEL ---------\", label)\n",
        "          for word in test_txt.split():\n",
        "            #tf = self.tf_dict[label][word]\n",
        "            #icf = self.icf_dict.get(word,0)\n",
        "            #log_prob_dict[label] += self.tf_icf_dict[label][word] / (sum(self.tf_dict[label].values()) + len(self.icf_dict))\n",
        "            if label in log_prob_dict:\n",
        "              if word in self.tf_idf_dict[label]:\n",
        "                log_prob_dict[label] += self.tf_idf_dict[label][word]\n",
        "              else:\n",
        "                log_prob_dict[label] += 0\n",
        "            else:\n",
        "              log_prob_dict.update({label:0})\n",
        "\n",
        "  #----------------------------------------------------------------------Multiplying term queries with category priors-------------------------------------------------------------------------------#\n",
        "        for label in cat_prob_dict.keys():\n",
        "          log_prob_dict[label] = log_prob_dict[label]*cat_prob_dict[label]\n",
        "\n",
        "          #print('HI')f\n",
        "\n",
        "      res_class = None\n",
        "      # Initialize the maximum value to negative infinity\n",
        "      max_log_prob = float('-inf')\n",
        "      # Iterate over the category and the corresponding label values to get the maximum value of probability and then return the corresponding class.\n",
        "\n",
        "      for label, log_prob in log_prob_dict.items():\n",
        "        #print(log_prob)\n",
        "        if log_prob > max_log_prob:\n",
        "          max_class = label\n",
        "          max_log_prob = log_prob\n",
        "      return max_class"
      ],
      "metadata": {
        "id": "TIrFUOr8QMKm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metric_eval(res_category,y_test):\n",
        "  eval_dict = {'Accuracy': 0, 'Precision': 0, 'Recall': 0 , 'F1-Score':0}\n",
        "  lst = []\n",
        "\n",
        "  # ------Accuracy---------#\n",
        "  total_samples = y_test.shape[0]\n",
        "  count = 0\n",
        "  j = 0\n",
        "  for i in y_test.index:\n",
        "    if(y_test[i]==res_category[j]):\n",
        "      #print('HI')\n",
        "      count = count+1\n",
        "    j = j + 1\n",
        "  lst.append((count/total_samples)*100)\n",
        "\n",
        "  #--------Precision---------#\n",
        "  lst.append(precision_score(y_test, res_category,average=\"macro\"))\n",
        "\n",
        "  #--------Recall------------#\n",
        "\n",
        "  lst.append(recall_score(y_test, res_category,average=\"macro\"))\n",
        "\n",
        "  #--------F-1-Score--------#\n",
        "\n",
        "  lst.append(f1_score(y_test, res_category,average=\"macro\"))\n",
        "  \n",
        "  itr = 0\n",
        "  for key in eval_dict.keys():\n",
        "    if key in eval_dict.keys():\n",
        "     eval_dict.update({key:lst[itr]})\n",
        "    itr = itr+1\n",
        "  return eval_dict"
      ],
      "metadata": {
        "id": "7XsqXqHu0pgd"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise the Classifier to get the final predictions\n",
        "def run_main(mode,split,stem_on,lemma_on):\n",
        "      # Initialise the Classifier to get the final predictions\n",
        "      my_NB_cf = NaiveBayesClassifier()\n",
        "      # Implementing the preprocessing on the etnire Training Dataframe\n",
        "      for i in range(train_df.shape[0]):\n",
        "         X['Text'][i] = my_preprocess_text(train_df['Text'][i], stem_on,lemma_on)\n",
        "        # Get the Text in the new dataframe. Used for processing further.\n",
        "      X_train,X_test, y_train, y_test = get_split(X,y,split)\n",
        "      tf_dict,my_vocab = get_tf(X_train,y_train)\n",
        "      all_doc_train = len(X_train)\n",
        "      icf_dict = get_icf(tf_dict, my_vocab, all_class)\n",
        "      idf_dict = get_idf(my_vocab,all_doc_train)\n",
        "      tf_icf_dict = get_tf_icf(tf_dict,icf_dict)\n",
        "      tf_idf_dict = get_tf_idf(tf_dict,idf_dict)\n",
        "      my_NB_cf.train(X_train,y_train,tf_dict,icf_dict,tf_icf_dict,tf_idf_dict)\n",
        "      res_category = []\n",
        "      for i in X_test.index:\n",
        "        test_document = X_test['Text'][i]\n",
        "        if(mode == 'TF-ICF'):\n",
        "          predicted_category = my_NB_cf.predict(test_document)\n",
        "        elif(mode == 'TF-IDF'):\n",
        "          predicted_category = my_NB_cf.predict_tf_idf(test_document)\n",
        "        else:\n",
        "          print('INVALID MODE')\n",
        "        res_category.append(predicted_category)\n",
        "      # After prediction,evaluate the performance on different metrics\n",
        "      #print(res_category)\n",
        "      metric = get_metric_eval(res_category,y_test)\n",
        "      return metric"
      ],
      "metadata": {
        "id": "GyQJAgwM49l2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Testing the Naive Bayes classifier with TF-ICF:\n",
        "\n",
        "● Use the testing set to evaluate the performance of the classifier.\n",
        "\n",
        "● Classify each document in the testing set and compare the predicted category with the actual category.\n",
        "\n",
        "● Calculate the accuracy, precision, recall, and F1 score of the classifier."
      ],
      "metadata": {
        "id": "2ZyXmPJTQMxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.mode.chained_assignment = None"
      ],
      "metadata": {
        "id": "4pOk9bssD3ae"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-ICF',0.20,'No','Yes')"
      ],
      "metadata": {
        "id": "kXbp3QjQQR1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10231c75-4099-45a9-d8fa-160a323c9120"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  1192\n",
            "The no. of samples in the Test Set is as  298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 96.30872483221476,\n",
              " 'Precision': 0.9646332814825966,\n",
              " 'Recall': 0.9623953658282016,\n",
              " 'F1-Score': 0.9627989033516539}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Improving the classifier:\n",
        "\n",
        "● Experiment with different preprocessing techniques and parameters to improve the performance of the classifier( including different splits like 60-40,80-20, 50-50).\n",
        "\n",
        "● Try using different types of features such as n-grams or TF-IDF weights.\n",
        "\n",
        "● Evaluate the performance of the classifier after each experiment and compare it with the previous results."
      ],
      "metadata": {
        "id": "xu_td0L1QS2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.1 Evaluating Train-Test Splits for TF-ICF Weighting Scheme"
      ],
      "metadata": {
        "id": "svZEvSPq68Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-ICF',0.30,'No','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuYy6z3V67vH",
        "outputId": "ffe5fdf2-6ae9-4237-f8f9-9b4b68534f90"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  1043\n",
            "The no. of samples in the Test Set is as  447\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 95.74944071588367,\n",
              " 'Precision': 0.9562714617587795,\n",
              " 'Recall': 0.9559947739614486,\n",
              " 'F1-Score': 0.9556439435912824}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-ICF',0.40,'No','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WrDPsZB67cb",
        "outputId": "f273deb4-b82e-483d-ab52-e1880537cab2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  894\n",
            "The no. of samples in the Test Set is as  596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 95.46979865771812,\n",
              " 'Precision': 0.9550386275434983,\n",
              " 'Recall': 0.9546563019040082,\n",
              " 'F1-Score': 0.954008947555949}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-ICF',0.50,'No','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-kY9jx567TR",
        "outputId": "f9de64c7-12af-41b2-d5a0-5344e1efe187"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  745\n",
            "The no. of samples in the Test Set is as  745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 94.8993288590604,\n",
              " 'Precision': 0.9480129743102547,\n",
              " 'Recall': 0.947162776396353,\n",
              " 'F1-Score': 0.9472899291692112}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.2  Evaluating Train-Test Split for TF-ICF Weighting Scheme"
      ],
      "metadata": {
        "id": "qQOZRTbv78xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-IDF',0.20,'No','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ueh_dw-67Kl",
        "outputId": "1a23cff8-ef71-4c0b-da37-e3f4d88ed6cc"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  1192\n",
            "The no. of samples in the Test Set is as  298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 89.26174496644296,\n",
              " 'Precision': 0.9129645979543755,\n",
              " 'Recall': 0.8835350157089288,\n",
              " 'F1-Score': 0.8890271804644924}"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-IDF',0.30,'No','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZZWN87466_V",
        "outputId": "ba100cec-16fa-440a-e8ce-b4ea64a1151f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  1043\n",
            "The no. of samples in the Test Set is as  447\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 91.2751677852349,\n",
              " 'Precision': 0.9278884811999948,\n",
              " 'Recall': 0.9039195289134916,\n",
              " 'F1-Score': 0.9096859665156701}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-IDF',0.40,'No','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgMgvqvN72OF",
        "outputId": "db608b9d-b700-4c86-c182-a840a235c722"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  894\n",
            "The no. of samples in the Test Set is as  596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 88.9261744966443,\n",
              " 'Precision': 0.9070694980694981,\n",
              " 'Recall': 0.8786807144605309,\n",
              " 'F1-Score': 0.8801908393557332}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-IDF',0.50,'No','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMq8Mpaj8PZH",
        "outputId": "3d9f89ed-fe5a-4e88-a4bd-2b9431fd9f39"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  745\n",
            "The no. of samples in the Test Set is as  745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 90.06711409395973,\n",
              " 'Precision': 0.92055353226113,\n",
              " 'Recall': 0.8907244953266218,\n",
              " 'F1-Score': 0.8979780062834362}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.3 Evaluating with both Stemming and Lemmatization \n"
      ],
      "metadata": {
        "id": "60x2XYTaAOTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-ICF',0.20,'Yes','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJbgTpkrANkj",
        "outputId": "d9481d09-0473-4319-d99b-ef70e4844a0c"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  1192\n",
            "The no. of samples in the Test Set is as  298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 94.96644295302013,\n",
              " 'Precision': 0.9519709272530781,\n",
              " 'Recall': 0.9478499112827471,\n",
              " 'F1-Score': 0.9483557857819935}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-ICF',0.30,'Yes','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5snPIWiPAY22",
        "outputId": "c9b4d47e-840c-47a4-cf2e-b8c9844dd2a7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  1043\n",
            "The no. of samples in the Test Set is as  447\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 94.85458612975391,\n",
              " 'Precision': 0.9480498874190826,\n",
              " 'Recall': 0.9468225809447736,\n",
              " 'F1-Score': 0.9470399493393687}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-ICF',0.40,'Yes','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5G6HHn4AYu1",
        "outputId": "4731a689-12e6-40da-c404-999c307e06a7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  894\n",
            "The no. of samples in the Test Set is as  596\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 95.46979865771812,\n",
              " 'Precision': 0.9546372083591017,\n",
              " 'Recall': 0.954727835874625,\n",
              " 'F1-Score': 0.9537990504388059}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_main('TF-ICF',0.50,'Yes','Yes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhUc4DV3AYmj",
        "outputId": "e2e44d9f-adf4-4080-b279-7d97498a8720"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The no. of samples in Training Set is as :  745\n",
            "The no. of samples in the Test Set is as  745\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Accuracy': 95.30201342281879,\n",
              " 'Precision': 0.9527718768293612,\n",
              " 'Recall': 0.951968931311997,\n",
              " 'F1-Score': 0.952003013126053}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Conclusion:\n",
        "\n",
        "● Write a brief report summarizing your findings.\n",
        "\n",
        "● Discuss the performance of the classifier and the impact of different preprocessing techniques, features, and weighting schemes on the results."
      ],
      "metadata": {
        "id": "t5xedxzVQd6a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESULT \n",
        "\n",
        "\n",
        "1.   The better scheme amongst TF-IDF and TF-ICF is TF-IDF on the basis of evaluated metric as accuracy.\n",
        "2.   Amongsts all the train - test splits evaluated, a best train-test split is 80:20 as it gives the highest accuracy on the test set. \n",
        "\n"
      ],
      "metadata": {
        "id": "qCM5O_ph7PNm"
      }
    }
  ]
}